{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-923f3ef75fbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.metrics'"
     ]
    }
   ],
   "source": [
    "from model import *\n",
    "from data import *\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.metrics import *\n",
    "\n",
    "from keras.metrics import *\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = './data/sky/iphone_full'\n",
    "images_dir = 'val'\n",
    "masks_dir = 'val_labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_wieghts = ['./models/Unet_modify_100.27-0.97.hdf5',\n",
    "                 './models/Unet_modify_100.49-0.98.hdf5',\n",
    "                  './models/Unet_modify_500.29-0.99.hdf5',\n",
    "                 './models/Unet_modify_500.54-0.99.hdf5',\n",
    "                 './models/Unet_modify_1000.28-0.99.hdf5',\n",
    "                 './models/Unet_modify_full.30-0.99.hdf5',\n",
    "                 './models/Unet.104-0.99_b.hdf5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_names = ['Accuracy', 'F1 score', 'IoU score']\n",
    "models_labels = ['Unet with ResNet 50 as encoder trained on 100 images (30 epochs).',\n",
    "                 'Unet with ResNet 50 as encoder trained on 100 images (50 epochs).',\n",
    "                 'Unet with ResNet 50 as encoder trained on 500 images (30 epochs).',\n",
    "                'Unet with ResNet 50 as encoder trained on 500 images (50 epochs).',\n",
    "                'Unet with ResNet 50 as encoder trained on 1000 images (30 epochs).',\n",
    "                'Unet with ResNet 50 as encoder trained on 1263 images (30 epochs).',\n",
    "                'Unet with ResNet 50 as encoder trained on 1263 images (104 epochs).']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_masks_lists(data_path, images_dir, masks_dir):\n",
    "    true_masks = glob.glob(os.path.join(data_path, (masks_dir + '/*')))\n",
    "    true_masks.sort()\n",
    "    \n",
    "    images = glob.glob(os.path.join(data_path, (images_dir + '/*')))\n",
    "    images.sort()\n",
    "    \n",
    "    return true_masks, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_sc(y_true, y_pred):\n",
    "    metric = mean_iou(labels=y_true, predictions=y_pred, num_classes=2)\n",
    "    return metric\n",
    "\n",
    "def f1_sc(y_true, y_pred):\n",
    "    p = precision(labels=y_true, predictions=y_pred)\n",
    "    r = recall(labels=y_true, predictions=y_pred)\n",
    "    \n",
    "    result = tf.multiply(tf.constant(2, dtype=tf.float32), tf.divide(tf.multiply(p, r), tf.add(p, r)))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def ac_sc(y_true, y_pred):\n",
    "    metric = accuracy(labels=y_true, predictions=y_pred)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(model_wts, model, images, true_masks, round_func):    \n",
    "    result = []\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    lab_placeholder = tf.placeholder(np.float64, shape=(256, 256))\n",
    "    pred_placeholder = tf.placeholder(np.float64, shape=(256, 256))\n",
    "\n",
    "    metric_1 = iou_sc(lab_placeholder, pred_placeholder)\n",
    "    metric_2 = f1_sc(lab_placeholder, pred_placeholder)\n",
    "    metric_3 = ac_sc(lab_placeholder, pred_placeholder)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    for weigths_path in model_wts:        \n",
    "        model.load_weights(weigths_path)\n",
    "        \n",
    "        ac_scores = []\n",
    "        f1_scores = []\n",
    "        iou_scores = []\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            image = cv2.imread(images[i])\n",
    "            image = cv2.cvtColor(image, code=cv2.COLOR_BGR2RGB) / 255.\n",
    "            image = cv2.resize(image, (256, 256))\n",
    "            image = np.expand_dims(image, 0)\n",
    "\n",
    "            true_mask = cv2.imread(true_masks[i], 0)\n",
    "            true_mask = cv2.resize(true_mask, (256, 256))\n",
    "            true_mask = true_mask / 255.\n",
    "            true_mask[true_mask > 0.5] = 1\n",
    "            true_mask[true_mask <= 0.5] = 0\n",
    "\n",
    "            pred_mask = model.predict(image)[0,:,:,0]\n",
    "\n",
    "            true_mask = true_mask.astype(np.float64)\n",
    "            pred_mask = round_func(pred_mask).astype(np.float64)\n",
    "\n",
    "            ac_scores.append(sess.run([metric_3], feed_dict={lab_placeholder: true_mask, pred_placeholder: pred_mask})[0])\n",
    "            f1_scores.append(sess.run([metric_2], feed_dict={lab_placeholder: true_mask, pred_placeholder: pred_mask})[0])\n",
    "            iou_scores.append(sess.run([metric_1], feed_dict={lab_placeholder: true_mask, pred_placeholder: pred_mask})[0])        \n",
    "        \n",
    "        mean_ac_score = np.mean(np.array(ac_scores)[:, 1])\n",
    "        mean_f1_score = np.mean(np.array(f1_scores)[:, 1])\n",
    "        mean_iou_score = np.mean(np.array(iou_scores)[:, 0])\n",
    "        \n",
    "        result.append((mean_ac_score, mean_f1_score, mean_iou_score))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(model_label, metrics):\n",
    "    print('[INFO] :: {}'.format(model_label))\n",
    "    for metric in metrics:\n",
    "        print('{0} : {1}'.format(metric[0], metric[1]))\n",
    "    print('_________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnd(value):\n",
    "    return value.round()\n",
    "\n",
    "def threshold(value):\n",
    "    \n",
    "    value = cv2.normalize(value, None, 255,0, cv2.NORM_MINMAX, cv2.CV_8UC1)\n",
    "    _,thresh = cv2.threshold(value, 0, 1, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    return thresh\n",
    "\n",
    "def threshold_and_contour(value):\n",
    "    \n",
    "    value = cv2.normalize(value, None, 255,0, cv2.NORM_MINMAX, cv2.CV_8UC1)\n",
    "    _,thresh = cv2.threshold(value, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    _, contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    contour_list = []\n",
    "    area_threshold = 500\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > area_threshold :\n",
    "            contour_list.append(contour)\n",
    "\n",
    "    countMask = np.zeros(thresh.shape, dtype='uint8')\n",
    "    cv2.drawContours(countMask, contour_list, -1, (255, 255, 255), cv2.FILLED)\n",
    "    \n",
    "    res_mask = cv2.bitwise_not(np.add(cv2.bitwise_not(thresh), cv2.bitwise_not(countMask)))\n",
    "    \n",
    "    res_mask = cv2.normalize(res_mask, None, 1,0, cv2.NORM_MINMAX, cv2.CV_8UC1)\n",
    "    \n",
    "    return res_mask\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/.virtenvs/FaceIidentification/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "/home/dmitrii/sky_detect/Semantic-Segmentation-Suite/UNET/sky-segmentation/keras_unet/model.py:79: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
      "  model = Model(input = inputs, output = conv10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] :: Unet with ResNet 50 as encoder trained on 100 images (30 epochs).\n",
      "Accuracy : 0.9803081750869751\n",
      "F1 score : 0.9770065546035767\n",
      "IoU score : 0.9239333868026733\n",
      "_________________________________\n",
      "[INFO] :: Unet with ResNet 50 as encoder trained on 100 images (50 epochs).\n",
      "Accuracy : 0.9770894646644592\n",
      "F1 score : 0.9748114347457886\n",
      "IoU score : 0.9546597003936768\n",
      "_________________________________\n",
      "[INFO] :: Unet with ResNet 50 as encoder trained on 500 images (30 epochs).\n",
      "Accuracy : 0.9802210330963135\n",
      "F1 score : 0.978460967540741\n",
      "IoU score : 0.9606500864028931\n",
      "_________________________________\n",
      "[INFO] :: Unet with ResNet 50 as encoder trained on 500 images (50 epochs).\n",
      "Accuracy : 0.9831638336181641\n",
      "F1 score : 0.9817739725112915\n",
      "IoU score : 0.9665442109107971\n",
      "_________________________________\n",
      "[INFO] :: Unet with ResNet 50 as encoder trained on 1000 images (30 epochs).\n",
      "Accuracy : 0.9850782752037048\n",
      "F1 score : 0.983899712562561\n",
      "IoU score : 0.9703385829925537\n",
      "_________________________________\n",
      "[INFO] :: Unet with ResNet 50 as encoder trained on 1263 images (30 epochs).\n",
      "Accuracy : 0.98597651720047\n",
      "F1 score : 0.984893798828125\n",
      "IoU score : 0.9721966981887817\n",
      "_________________________________\n",
      "[INFO] :: Unet with ResNet 50 as encoder trained on 1263 images (104 epochs).\n",
      "Accuracy : 0.986231803894043\n",
      "F1 score : 0.9851776361465454\n",
      "IoU score : 0.9726364612579346\n",
      "_________________________________\n"
     ]
    }
   ],
   "source": [
    "msks, imgs = images_masks_lists(data_path=data, images_dir=images_dir, masks_dir=masks_dir)\n",
    "model = unet_modify()\n",
    "\n",
    "num = 0\n",
    "for metrics in calc_metrics(models_wieghts, model, imgs, msks, threshold_and_contour):\n",
    "    model_label = models_labels[num]\n",
    "    metrics = [(metrics_names[i], metrics[i]) for i in range(3)]\n",
    "    num += 1\n",
    "    \n",
    "    print_metrics(model_label, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
