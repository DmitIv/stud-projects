{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from model import *\n",
    "from data import *\n",
    "import ImageTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitri/dev/BachelorDiploma/venv/lib/python3.8/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "/home/dmitri/dev/BachelorDiploma/model.py:78: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
      "  model = Model(input = inputs, output = conv10)\n"
     ]
    }
   ],
   "source": [
    "unet_m = unet_modify()\n",
    "MODELS = [\n",
    "{'model_name':'Unet_modify_500',\n",
    "           'model' : unet_m,\n",
    "           'train':'data/skyFinder',\n",
    "           'val'  :'data/skyFinder',\n",
    "         'icm' : 'rgb'},]\n",
    "\n",
    "LOGS_PATH = './log'\n",
    "if not os.path.exists(LOGS_PATH):\n",
    "    os.makedirs(LOGS_PATH)\n",
    "    \n",
    "WEIGHTS_PATH = './models'\n",
    "if not os.path.exists(WEIGHTS_PATH):\n",
    "    os.makedirs(WEIGHTS_PATH)\n",
    "    \n",
    "BATCH_SIZE = 5\n",
    "VAL_BATCH_SIZE = 5\n",
    "EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(\n",
    "    rotation_range=0.3,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7587 images belonging to 1 classes.\n",
      "Found 7587 images belonging to 1 classes.\n",
      "Found 3495 images belonging to 1 classes.\n",
      "Found 3495 images belonging to 1 classes.\n",
      "Epoch 1/50\n",
      "1517/1517 [==============================] - 933s 615ms/step - loss: 0.1920 - accuracy: 0.9347 - val_loss: 0.2618 - val_accuracy: 0.8848\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitri/dev/BachelorDiploma/venv/lib/python3.8/site-packages/keras/callbacks/callbacks.py:706: RuntimeWarning: Can save best model only with acc available, skipping.\n",
      "  warnings.warn('Can save best model only with %s available, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 387/1517 [======>.......................] - ETA: 10:01 - loss: 0.1670 - accuracy: 0.9450"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "for model in MODELS:\n",
    "#     lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=1e-6)\n",
    "\n",
    "    weights_name = model['model_name'] + '.{epoch:02d}.hdf5'\n",
    "    weights_dir = os.path.join(WEIGHTS_PATH, weights_name)\n",
    "    checkpoint = ModelCheckpoint(weights_dir, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    train_generator = BatchGenerator(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        train_path=model['train'],\n",
    "        image_folder='train',\n",
    "        mask_folder='train_labels',\n",
    "        aug_dict=data_gen_args,\n",
    "        save_to_dir = None,\n",
    "        image_color_mode = model['icm']\n",
    "    )\n",
    "\n",
    "    val_generator = BatchGenerator(\n",
    "        batch_size=VAL_BATCH_SIZE,\n",
    "        train_path=model['val'],\n",
    "        image_folder='val',\n",
    "        mask_folder='val_labels',\n",
    "        aug_dict=data_gen_args,\n",
    "        save_to_dir = None,\n",
    "        image_color_mode = model['icm'])\n",
    "\n",
    "    CURRENT_TIME = str(time.strftime(\"%Y%m%d-%H%M%S\"))    \n",
    "    log_name = \"{}_{}\".format(model['model_name'], CURRENT_TIME)\n",
    "    log_dir = os.path.join(LOGS_PATH, log_name)\n",
    "    os.makedirs(log_dir)\n",
    "#     tbCallBack = ImageTB.ImagesTensorBoard(log_dir=log_dir, generator=val_generator)\n",
    "\n",
    "    model = model['model']\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=EPOCH,\n",
    "        callbacks=[\n",
    "\n",
    "                checkpoint\n",
    "            ],\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=len(val_generator),\n",
    "\n",
    "        max_queue_size=8,\n",
    "        workers=4,\n",
    "        use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
