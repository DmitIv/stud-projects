{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "from data_utils import SegItemListCustom, ImageListVertical\n",
    "from data import data_dirs as data_env, get_label_with_context\n",
    "\n",
    "from result_visualization import show_results\n",
    "\n",
    "from fastai.vision import (\n",
    "    Learner, load_learner,\n",
    "    open_image, open_mask,\n",
    "    ImageList,\n",
    "    get_transforms, imagenet_stats,\n",
    "    ResizeMethod, DatasetType,\n",
    "    plt,   # matplotlib.pyplot\n",
    "    nn,    # torch.nn\n",
    "    optim  # torch.optim\n",
    ")\n",
    "from fastai.callbacks.mem import PeakMemMetric\n",
    "\n",
    "from torchvision.utils import save_image as t_save\n",
    "\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "AREA_THRESHOLD = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = load_learner(\"/home/dmitri/Documents/model_weights/linknet34/\", \"linknet34_osp_full_e25_exp_without_logit_1e-03_dropout_10\")\n",
    "# learner = learner.load(\"/home/dmitri/Documents/model_weights/linknet34/linknet34_ops_full_e100_wghts\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unlabeled_image in data_env.get_subdir(\"train images raw\").iterdir():\n",
    "    img = open_image(unlabeled_image).resize(256)\n",
    "    label_name = get_label_with_context(unlabeled_image)\n",
    "    label = learner.predict(img)\n",
    "    lable_np_array = label[1].numpy() * 254\n",
    "    \n",
    "    blur = cv2.GaussianBlur(lable_np_array.astype(np.uint8),(5,5),0).squeeze(0)\n",
    "    ret,thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Contour detection\n",
    "    _, contours, hierarchy = cv2.findContours( thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter contour by area\n",
    "    contour_list = []\n",
    "    area_threshold = AREA_THRESHOLD\n",
    "    \n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > area_threshold :\n",
    "            contour_list.append(contour)\n",
    "    \n",
    "    # Making binary mask by contour        \n",
    "    countMask = np.zeros(thresh.shape, dtype='uint8')\n",
    "    cv2.drawContours(countMask, contour_list, -1, (255, 255, 255), cv2.FILLED)\n",
    "    \n",
    "    # Restore accuracy of board between sky and other objects\n",
    "    mask_rev = np.add(cv2.bitwise_not(thresh), cv2.bitwise_not(countMask))\n",
    "    _,mask_rev = cv2.threshold(mask_rev, 0, 255, cv2.THRESH_BINARY)\n",
    "    mask = cv2.bitwise_not(mask_rev) \n",
    "    \n",
    "    t_save(torch.from_numpy(mask).to('cpu', torch.float), label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
