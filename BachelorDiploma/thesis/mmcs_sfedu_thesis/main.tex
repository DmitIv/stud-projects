\usepackage{amsmath}
\usepackage{cleveref}
\usepackage[toc,page]{appendix}
\usepackage{listings}
% В этом файле следует писать текст работы, разбивая его на
% разделы (section), подразделы (subsection) и, если нужно,
% главы (chapter).

% Предварительно следует указать необходимую информацию
% в файле SETUP.tex

\input{preamble.tex}

\lstset
{ %Formatting for code in appendix
    language=Python,
    basicstyle=\footnotesize,
    numbers=left,
    stepnumber=1,
    showstringspaces=false,
    tabsize=1,
    breaklines=true,
    breakatwhitespace=false,
}

\begin{document}

\Intro

В рамках данной работы освещается вопрос семантического анализа изображений путем применения глубоких сверточных нейронных сетей.
Под семантическим анализом понимается получение из изображения какой-либо интерпретируемой информации: расположение объектов на сцене,
принадлежность объектов к заранее заданным классам, наличие на изображении объектов определённого типа и т.п..
Данная тема будет рассмотрена на примере задачи обнаружения и выделения неба на изображениях.
Входными данными задачи являются фотографии, сделанные на камеры мобильных устройств.
Специализированный домен изображений был выбран с целью упрощения адаптация потенциального решения к применению в конечных продуктах,
таких как пользовательское программное обеспечение для смартфонов.
Решением задачи выступают сгенерированные для входных фотографий полутоновые изображения.
Такое изображение называется сегментационной маской и для каждого пикселя исходной фотографии выражает его принадлежность
к региону неба: белый цвет интерпретируется как положительный результат, черный - как отрицательный.
В ходе разработки алгоритма решения задачи была исследована эффективность применения различных подходов к генерации подобного рода масок - сегментации.
Сравнения эффективности проходило по индексу Жаккара - в западной литературе также встречается название intersection over union, IoU\@.
Для решения задачи сегментации из наиболее эффективных подходов был составлен стек алгоритмов: применение к входному изображению глубокой сверточной сети
с последующей корректировкой методами компьютерного зрения полученной маски.
В ходе обучения модели искусственной нейронной сети, ИНС, для предотвращения переобучения и улучшения сходимости
применялись техники регуляризации, такие как learning rate decaying и cyclic learning rate.
Влияние данных подходов на решение также отражено в результатах работы.
В заключительной части хода разработки была рассмотрена возможность адаптация модели, обученной на данных датасета SkyFinder,
к выбранному домену изображений.
Данная техника имеет название Domain Adaptation и используется для улучшения качества на практических данных.

% Если typeOfWork в SETUP.tex задан как 2 или 3, то начинать% надо не с section (раздел), а с главы (chapter)

\section{Постановка и описание задачи}

Цифровая обработка изображений являются комплексной темой.
В нее входят задачи фильтрации, преобразования цвета, яркости и контрастности,
морфологической обработка, распознавания и выделения объектов на сцене~\autocite{gonzalez2008digital}.
Семантический анализу - подход, целью которого является получение интерпретируемой информации высших порядков об изображении.
К подзадачам семантического анализа можно отнести классификацию объектов на сцене, детекцию объектов и сегментацию изображений на семантические регионы.
В рамках текущей работы будет проведен разбор подзадачи сегментации.

\subsection{Задача сегментации}

Для возможности цифровой обработки и анализа будем рассматривать представление изображения как трёхмерного массива чисел,
имеющего ширину, количество столбцов, и высоту, количество строк, равными ширине и высоте изображения соответственно.
На каждой позиции по ширине и высоте будет находится вектор из трех целых чисел, из промежутка [0, 255], что
соответствует RGB модели представления цвета пикселя изображения.
В таком случае сегментацией изображения будет являться отображение каждого RGB вектора в некоторое целое число.
Это число соответствует идентификатору некоторого класса.
При применение такого отображения ко всему изображению получается двумерный массив, ширина и высота которого
соответствуют таковым у исходного изображения.
Подобный двумерный массив будет разделять изображение на регионы по обозначенному признаку и называться сегментационной маской.
Сегментацию возможно рассматривать как попиксельную классификацию объектов.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/example_segmentation.png}
    \caption{Общий вид сегментации на примере данных датасета COCO}
    \label{fig:seg_example}
\end{figure}

Отметим, что описанное выше отображение может обладать относительно простой природой и учитывать только значение пикселя в конкретной позиции,
так и более сложной структурой, использующей информацию о распределении цветов во всем изображении, положении пикселя на изображении и
свойствах соседних пикселей, непосредственно соседствующих с обозреваемым значением или отступающих от него на заданное смещение~\autocite{liu2018recent}.
На~\ref{fig:seg_example} показан общий вид задачи сегментации изображения.

\subsection{Выделение неба в рамках задачи сегментации}

Описанная в введение задача выделения региона неба на входном изображении может быть рассмотрена как задача сегментации.
Так как в данном случае результирующих классов всегда два - класс принадлежности и обратный ему -, то имеется более узкий случай сегментации - бинарная.
Итоговая маска будет содержать только значения 0 и 1, представляя собой однобитовое бинарное изображение, что можно считать вырожденным полутоновым.

Таким образом, решение задачи выделения неба сводится к нахождению отображения из вектора цветов для каждого пикселя в целое число из промежутка [0, 1].
Данное отображение возможно получить как алгоритмами машинного зрения, так и с помощью использования моделей глубоких сверточных нейронных сетей.
В данной работе приводится решение методом нейронных сетей, при этом алгоритмы компьютерного зрения используются для корректировки полученной маски.
Под корректировкой здесь понимается обнаружение и удаление ложноположительных регионов неба небольшой площади.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/sky_segmentation.png}
    \caption{Пример, демонстрирующий работу алгоритма}
    \label{fig:sky_seg}
\end{figure}

Практическое применение подобного решения можно найти в пользовательских приложениях эстетической обработки пейзажных фотографий для смартфонов,
в автоматических системах мониторинга воздушного пространства, при извлечении семантической информации высшего порядка для использования в иных методах анализа
и обработки изображений~\autocite{7415405}.

\section{Обзор предметной области}

Задача семантического анализа изображений имеет широкое применение при решении различных прикладных и исследовательских
проблем~\autocite{maier2018gentle}~\autocite{pan2019image}~\autocite{stabinger2020evaluating}~\autocite{li2015brief},
в связи с чем активно изучается.
Сегментации изображений, в частности, нашли применения в таких областях как проведение хирургических операций,
автопилотируемый транспорт, автоматизированное картографирование местности~\autocite{liu2018recent}.
Ниже приведен краткий обзор исследований, темы которых связаны с поставленной задачей.
Результаты этих исследований в разной степени использовались для построения решения.

\subsection{Сегментация изображений}

До начала активного применения глубоких нейронных сетей в задачах сегментации использовались методы компьютерного зрения,
основанные на применении порогов бинаризации для полутоновых изображений, выявлении признаков,
кластеризации методом k-средних~\autocite{10.5555/1888028.1888043}~\autocite{10.5555/540298}~\autocite{inproceedings}.
Каждый из этих подходов имеет свои преимущества, метод бинарной сегментации полутоновых изображений до сих пор успешно применяется
в области анализа медицинских данных~\autocite{bookMedicalImages}.
Но применение данных подходов к задаче выделения границы между объектами путем сегментации показало худшие результаты в сравнении с FCN,
полностью сверточными глубокими сетями~\autocite{7966418}.

Современные решения задачи сегментации в различных областях зачастую опираются на применение нейронных сетей~\autocite{feng2019deep}.
Наиболее распространёнными архитектурами являются Unet, DeepLab, RefineNet~\autocite{ronneberger2015unet}~\autocite{chen2016deeplab}~\autocite{lin2016refinenet}.
Имеются исследования применения архитектуры RefineNet для определения региона неба на датасете SkyFinder~\autocite{place2017segmenting}.

\subsection{Способы регуляризации}

Помимо специализированных решений задачи сегментации, были рассмотрены также общие методики, применяемые для обучения глубоких нейронных сетей.
При высокой сложности модели, в процессе обучения она может начать отражать в ответах шум в тренировочных данных~\autocite{salman2019overfitting}~\autocite{ghojogh2019theory}.
Данное явление называется переобучением, overfitting.
С целью снизить вероятность его проявление применяются разнообразные техники регуляризации: dropout, нормализация значений между слоями сети,
настройка гиперпараметров процесса обучения~\autocite{smith2018disciplined}~\autocite{labach2019survey}~\autocite{ioffe2015batch}.

\section{Метод решения}

Конечное решение задачи сегментации имеет комплексное строение.
Изображение, поступающее на вход решающему алгоритму, обрабатывается ИНС.
Результатом такого применения является двумерный массив пар.
Каждое значение в паре обозначает вероятность принадлежности одному из двух классов.
Для получения сегментационной маски индекс максимального из двух значений расценивается как идентификатор класса: 1 для региона неба, 0 - обратный ему.
В ходе экспериментов было выявлено наличие артефактов в результатах классификации.
Для части изображений имелись ложноположительные регионы неба небольшой площади.
Для их устранения последовательно применялись алгоритмы FindCounters и DrawCounters из состава библиотеки OpenCV.

Для обучения сети использовался датасет SkyFinder.
Для улучшения показателя IoU на целевом домене изображений использовалась техника Unsupervised Domain Adaptation.
Это позволило уменьшить количество ложноположительных и ложноотрицательных регионов без дополнительной разметки обучающий выборки из фотографий,
сделанных на мобильные устройства.

\subsection{Глубокая сверточная сеть}

Как было отмечено выше, текущие исследования указывают на преимущества глубоких сверточных сетей в задачах семантического анализа
перед классическими алгоритмами компьютерного зрения.
Глубокими сверточными сетями называют подмножество искусственных нейронных сетей, все полносвязные слои которых заменены сверточными.

Архитектура сети для решения задачи сегментации представляется двумя частями.
Отбор признаков, downsampling path или енкодер, и генерализация результатов отбора, upsampling path или декодер.
Для решения проблемы потери информации в сверточных слоях, карты признаков с некоторых уровней нисходящей части объединяют с противоположными входами восходящей части.
На~\ref{fig:net_arch_common} приведена общая схема сети для задач сегментации.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/net_arch.png}
    \caption{Общий вид глубокой сверточной сети для задачи сегментации}
    \label{fig:net_arch_common}
\end{figure}

В нисходящей части используются сверточные слои (отмечены желтым цветом на~\ref{fig:net_arch_common}),
слои с выбором наибольшего значения по ядру - max pooling (отмечены красным цветом на~\ref{fig:net_arch_common}).
На сверточных слоях к входным данным применяются ядра свертки.
Количество ядер определяет для слоя количество выходных карт признаков.
Выходные карты признаков подаются на вход следующему слою.
К выходным картам применяется функция активации (отмечены оранжевым цветом на~\ref{fig:net_arch_common}).
Значения в ядрах свертки являются обучаемыми параметрами сети.
Ниже приведена формула для простого случая двумерного входного массива и двумерного ядра свертки~\eqref{eq:1} при единичном шаге.

\begin{equation}
    \label{eq:1}
    G_{m, n} = (f*h)[m, n] = \sum_{j}{\sum_{k}{h_{j, k} f_{m + j, n + k}}}
\end{equation}

где f - входной массив данных, h - ядро свертки, G - выходная карта признаков.

Размеры каждой карты определяются размерами входных данных, размерами ядра, размером добавочного отступа по краям массива данных и сдвигом,
на которое ядро смещается по массиву~\eqref{eq:2}.

\begin{equation}
    \label{eq:2}
    output = \frac{input + 2 * p - k}{s} + 1
\end{equation}

где output - размеры выходной карты признаков, input - размеры входного массива данных, p - величина отступа, добавляемого к краям массива (padding),
k - размеры ядра свертки, s - сдвиг ядра.

В слоях с выбором наибольшего значения ядро определяет только размеры окна, в котором выбирается максимальный элемент~\eqref{eq:3}.
Операции сложения и умножения на этом слое не используются.

\begin{equation}
    \label{eq:3}
    G_{i, j} = \max_{(k, l) \in N}{F_{i + k, j + l}}
\end{equation}

где

\begin{equation}
    \label{eq:4}
    N = \{0, .. , \text{kernel size}\}
\end{equation}

G - выходная карта признаков, F - входной массив данных.

В качестве функции активации используется rectified linear unit, ReLU~\eqref{eq:5}.

\begin{equation}
    \label{eq:5}
    g(x) =
    \begin{cases}
        0 &x < 0 \\
        x &x \geq 0
    \end{cases}
\end{equation}

В upsampling части сети используются, помимо сверточных, транспонированные сверточные слои (отмечены синим цветом на~\ref{fig:net_arch_common}).
Прежде чем описать оператор транспонированной свертки, необходимо рассмотреть применение сверточного ядра к входным данным,
как произведение матриц.
Рассмотрим на примере ядра свертки размером $ 3 \times 3 $ и входного массива размером $ 4 \times 4 $.
Значение сдвига равно 1, дополнение отступом не используется.

$$
\setcounter{MaxMatrixCols}{20}
\small
\begin{equation}
    \label{eq:6}
    \begin{pmatrix}
         K_{0,0} & K_{0, 1} & K_{0, 2} & 0 & K_{1,0} & K_{1, 1} & K_{1, 2} & 0 & K_{2,0} & K_{2, 1} & K_{2, 2} & 0 & 0 & 0 & 0 & 0 \\
         0 & K_{0,0} & K_{0, 1} & K_{0, 2} & 0 & K_{1,0} & K_{1, 1} & K_{1, 2} & 0 & K_{2,0} & K_{2, 1} & K_{2, 2} & 0 & 0 & 0 & 0 \\
         0 & 0 & 0 & 0 & K_{0,0} & K_{0, 1} & K_{0, 2} & 0 & K_{1,0} & K_{1, 1} & K_{1, 2} & 0 & K_{2,0} & K_{2, 1} & K_{2, 2} & 0 \\
         0 & 0 & 0 & 0 & 0 & K_{0,0} & K_{0, 1} & K_{0, 2} & 0 & K_{1,0} & K_{1, 1} & K_{1, 2} & 0 & K_{2,0} & K_{2, 1} & K_{2, 2} \\
    \end{pmatrix}

\end{equation}

\small
\begin{equation}
    \label{eq:7}
    \begin{pmatrix}
         W_{0,0} & W_{0, 1} & W_{0, 2} & W_{0, 3} & W_{1,0} & W_{1, 1} & W_{1, 2} & W_{1, 3} & W_{2,0} & W_{2, 1} & W_{2, 2} & W_{2, 3} & W_{3,0} & W_{3, 1} & W_{3, 2} & W_{3, 3} \\
    \end{pmatrix}

\end{equation}
\normalsize
$$

В~\eqref{eq:6} введена матрица K, ненулевые элементы которой представлены значениями из ядра свертки.
$ K_{i,j} $ - элемент, стоящий в ядре на позиции i, j.
В~\eqref{eq:7} введена матрица I, полученная путем перекомпоновки входного массива данных в вектор по строкам.
Тогда карту признаков G размером $ 2 \times 2 $ можно получить путем умножения матрицы $ K $ на $ I^{T} $.

$$
\setcounter{MaxMatrixCols}{1}
\small
\begin{equation}
    \label{eq:8}
    K * I^{T} =
    \begin{pmatrix}
        & \sum_{j}{\sum_{k}{h_{j, k} f_{j, k}}}& \\
        & \sum_{j}{\sum_{k}{h_{j, k} f_{j, 1 + k}}}& \\
        & \sum_{j}{\sum_{k}{h_{j, k} f_{1 + j, k}}} & \\
        & \sum_{j}{\sum_{k}{h_{j, k} f_{1 + j, 1 + k}}} & \\
    \end{pmatrix}
\end{equation}
$$

Чтобы из~\eqref{eq:8} получить~\eqref{eq:1} необходимо записать матричное произведение, избавиться от нулевых слагаемых и объединить оставшиеся под знаками сумм.

$$
\setcounter{MaxMatrixCols}{1}
\small
\begin{equation}
    \label{eq:12}
    K * I^{T} =
    \begin{pmatrix}
        & G_{0, 0} & \\
        & G_{0, 1} & \\
        & G_{1, 0} & \\
        & G_{1, 1} & \\
    \end{pmatrix}
\end{equation}
$$

Введем транспонированную свертку для входных данных F размером $ 2 \times 2 $, ядра свертки H $ 3 \times 3 $ и выходной карты признаков G $ 4 \times 4 $,
как произведение $K^{T}$, полученной из H аналогично~\eqref{eq:6}, на $F_{0}^{T}$, полученный из F аналогично~\eqref{eq:7}.

$$
\setcounter{MaxMatrixCols}{1}
\small
\begin{equation}
    \label{eq:9}
    K^{T} * F_{0}^{T} =
    \begin{pmatrix}
         G_{0, 0}  \\
         G_{0, 1}  \\
         G_{0, 2}  \\
         G_{0, 3}  \\
         G_{1, 0}  \\
         G_{1, 1}  \\
         G_{1, 2}  \\
         G_{1, 3}  \\
         G_{2, 0}  \\
         G_{2, 1}  \\
         G_{2, 2}  \\
         G_{2, 3}  \\
         G_{3, 0}  \\
         G_{3, 1}  \\
         G_{3, 2}  \\
         G_{3, 3}  \\
    \end{pmatrix}
\end{equation}
$$

Таким образом~\eqref{eq:9} позволяет восстанавливать исходное количество пикселей для их классификации по выделенным признакам~\autocite{dumoulin2016guide}.
Отметим здесь, что сверточные слои в восходящей части не уменьшают размеры данных по высоте и ширине за счёт использования паддинга.

После выходного слоя размеры массива данных равняются $ N \times M \times C $, где $N$, $M$ - размеры исходного изображения, а $C$ - количество классов.
К полученным данным применяется логистическая функция, обобщённая на многомерный случай, softmax~\eqref{eq:10}.
Вычисления осуществляются для каждой позиции $ [n, m] $ по размерности $C$\@.

\begin{equation}
    \label{eq:10}
    Softmax(x_{i}) = \frac{{}e^{x_{i}}}{\sum_{j}e^{x_{j}}}
\end{equation}

В результате каждый вектор $\bar{v}$ из массива данных по размерности $C$ обладает следующими свойствами:

\begin{itemize}
    \item $v_{i} \in [0,1] \forall i \in [0, C]$ \\
    \item $\sum_{i=0}^{C} v_{i}=1$
\end{itemize}

Ниже приведен (~\ref{fig:softmax_debug_info}) отладочный вывод данных до и после softmax для программы, реализующей обучения глубокой сверточной сети с ResNet34 блоком в качестве downsampling части
и LinkNet в качестве upsampling.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/softmax_debug_info.png}
    \caption{Отладочная информация с визуализацией}
    \label{fig:softmax_debug_info}
\end{figure}

\subsection{Регуляризация на уровне архитектуры}

Как было отмечено в части обзора решений, при обучении сети может возникнуть overfitting.
Состояние модели, в котором она демонстрирует значительно более высокие метрики качества на тренировочных данных,
чем на тестовых.
Причиной такого поведения может быть запоминание шумов данных.
К ним могут быть отнесены статистические выбросы, неравномерное представление классов в выборке, фактическая природа данных.
В частности, при преобладании определённого признака в данных вероятно проявление ковариантного сдвига по признаку (Covariate Shift)~\autocite{covariateShift}.
Подобное смещение приводит к смещению на уровне внутренних слоев.
Для предотвращения влияния данные между слоями приводят к нормализованному состоянию~\eqref{eq:11}.
Нормализация совершается по пакету, batch.

\begin{equation}
    \centering
    \item $1.~~\mu_{\mathcal B} & = & \frac1m \sum_{i = 1}^m x_i $
    \item $2.~~\sigma^2_{\mathcal B} & = & \frac1m \sum_{i=1}^m (x_i - \mu_{\mathcal B})^2 $
    \item $3.~~\hat x_i & = & \frac{x_i - \mu_{\mathcal B}}{\sqrt{\sigma_{\mathcal B}^2 + \epsilon}} $
    \item $4.~~\mathrm{BN}_{\gamma,\beta}(x_i) & = & \gamma \hat x_i + \beta $
    \label{eq:11}
\end{equation}

Здесь $x_{i} \in X$, где $X$ - текущий пакет входных данных.
Этапы~\ref{eq:11}.1,~\ref{eq:11}.2,~\ref{eq:11}.3 применяются только на этапе обучения сети.
Параметры $\gamma$ и $\beta$ являются обучаемыми.
При инференсе сети они обеспечивают соответствие среднего и смещения для входных данных аналогичными показателями
тренировочных пакетов.
На~\ref{fig:batch_norm} продемонстрировано сравнение процессов обучения с и без описанной техники.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/batch_normalization.png}
    \caption{Улучшение сходимости нормализацией}
    \label{fig:batch_norm}
\end{figure}

\subsection{Извлечение признаков, енкодер часть}

Для выделение признаков рассматривались сети архитектуры ResNet.
Отличительной чертой данной архитектуры являются residual block и наличие skip connection.
В состав одного блока последовательно входят:

\begin{enumerate}
    \item Сверточный слой с паддингом
    \item Нормализация по пакету
    \item Активационная функция
    \item Сверточный слой с паддингом
    \item Нормализация по пакету
\end{enumerate}

Результат блока объединяется с входными данными.
Такое решение позволяет предотвратить затухание градиента при обратном распространении ошибки~\autocite{he2015deep}.

Для снижения размеров массива данных в архитектуре ResNet используются блоки, сочетающие в себе сверточный слой
с ядром $1 \times 1$, без паддинга и сдвигом в 2 и нормализацию по пакету.

В итоговое решение в качестве downsampling path вошла архитектура ResNet34.
Она обладает меньшим количеством тренируемых параметров в сравнении с ResNet50, ResNet101, ResNet152.
При этом демонстрируется достаточно высокое значение метрики качества.

\subsection{Генерализация признаков, декодер часть}

В downsampling части сети по извлеченным в енкодере признакам генерируется маска.
Для выбора декодера было проведено сравнение двух архитектурных решений: Unet~\autocite{ronneberger2015unet} и LinkNet~\autocite{chaurasia2017linknet}.
Оба подхода демонстрируют схожие значения метрики качества: усреднено $ 95.3 $ для LinkNet против $ 95.8 $ для Unet.
При этом за счет меньшего количества тренируемых параметров LinkNet имеет меньшее время обучения~(\ref{fig:time_dbg}) и быстрее обрабатывает изображение в инференсе.
Unet имеет $ 26,730,306 $ тренируемых параметра, LinkNet - $ 21,794,850 $.
Аналогично енкодер части, декодер имеет блочную структуру.
Состав каждого блока на примере варианта с использованием LinkNet подхода:

\begin{itemize}
    \item Сверточный слов с ядром $ 1 \times 1 $
    \item Нормализация по пакету
    \item Активационная функция
    \item Транспонированная свертка
    \item Нормализация по пакету
    \item Активационная функция
    \item Сверточный слой с ядром $ 1 \times 1 $
    \item Нормализация по пакету
    \item Активационная функция
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/decoder_outputs.png}
    \caption{Визуализация выходных карт признаков для различных уровней декодер части}
    \label{fig:dec_out}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/time_debug.png}
    \caption{Отладочная информация процесса обучения}
    \label{fig:time_dbg}
\end{figure}

\subsection{Функция потерь и метрика качества}

Для обучения сети по прецедентам методом обратного распространения ошибки необходимо ввести функцию потерь.
Данная функция отражает отклонение полученного сетью результата от образца.
Минимизации отклонения можно добиться с помощью градиентого спуска.

В данной работе в качестве функции потерь выступает логистическая функция ошибки~\eqref{eq:13}.
Встречаются так же названия бинарная кросс-энтропия, логлосс.

\begin{equation}
    \label{eq:13}
    f(y, \tilde{y}) =
    \begin{cases}
        -\log{(y)} & \tilde{y} = 1 \\
        -\log{(1 - y)} & \tilde{y} = 0 \\
    \end{cases}
\end{equation}

В приведённой формуле $ y $ - это предсказанный результат, а $ \tilde{y} $ - достоверный образец.
Значения образца 1 и 0 отражают принадлежность к целевому классу.
При обобщении функции на случай пакетного обучения получаем~\eqref{eq:14}.

\begin{equation}
    \label{eq:14}
    f(y, \tilde{y}) = -\frac{1}{n}\sum_{i=0}^{n}{(\tilde{y_{i}}\cdot\log{(y_{i})} + (1 - \tilde{y_{i}})\cdot\log{(1 - y_{i})})}
\end{equation}

Здесь $ y, \tilde{y} $ - пакеты размерами~$n$ ответов и образцов соответственно.
При пакетном обучении обновление весов происходит не после каждого образца,
а после каждого пакета - набора образцов.

Для оценки работы сети использовалась метрика intersection over union, индекс Жаккара.
Для каждой пары ответ-образец попиксельно вычисляются площади классифицированных сегментов.
Значением индекса для класса является отношение площади пересечения к площади объедения сегментов в паре в процентном отношении~\eqref{eq:18}.

Замечу, данная метрика чувствительная не только ложноотрицательным ошибкам при классификации.
При ложноотрицательном срабатывании для класса будет уменьшаться индекс за счет уменьшения площади пересечения.
При ложноположительном выделении пикселя в класс будет увеличиваться площадь пересечения, что так же негативно скажется на итогом значении метрики для класса.

\begin{equation}
    \label{eq:18}
    \mathrm{IoU} = \frac{\mathrm{S}_{intersection}}{\mathrm{S}_{union}} \cdot 100 \%
\end{equation}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/iou_vis.png}
    \caption{Визуалзиация intersection over union}
    \label{fig:iou_vis}
\end{figure}

\subsection{Регуляризация на уровне гиперпараметров сети}

Для улучшения сходимости и предотвращения явлений предобучения или переобучения можно добавлять различные гиперпараметры к сети такие, как learning rate и momentum.

\begin{equation}
    \label{eq:16}
    \omega_{i} = \omega_{j} - \alpha \cdot \frac{\delta f(y, \tilde{y})}{\delta\omega_{j}}
\end{equation}

При оптимизации функции потерь градиентным спуском движение к минимуму определяется градиентом.
Learning rate, коэффициент $\alpha$ при градиенте в~\eqref{eq:16}, отражает степень смещения относительно новых значений.
При достаточно большом значение ухудшится сходимость, но вероятность остаться в локальном минимуме будет меньше.
При маленьких значений коэффициента сходимость к минимуму улучшается, но и возникает проблема остаться в локальном минимуме.
В данном решение были рассмотрены два подхода к настройке данного значения в процессе обучения сети: learning rate decaying и cyclic learning rate.

При использовании learning rate decaying изначальное значение learning rate устанавливается относительно высоким.
В течении всего обучения это значения поэтапно уменьшается.
В качестве функции изменения коэффициента была выбрана fixed stepsize~\eqref{eq:15}, описанная в~\autocite{wu2019demystifying}.

\begin{equation}
    \label{eq:15}
    \alpha_{i} = \alpha_{j}^{c}
\end{equation}

Переход с шага $j$ на шаг $i$ путем возведения learning rate в степень осуществляется при разнице между предыдущем
и текущим значениями функции потерь меньшей $\varepsilon$.
В рамках данной работы $c$ равнялось 2, $\varepsilon$ равнялось $0.01$.

При cyclic learning rate значение постепенно снижается до определённого порога, а затем снова повышается.
Подход one cycle policy, рассмотренный в~\autocite{smith2018disciplined}, предлагает на протяжении всего процесса обучения расположить один полный цикл увеличения-уменьшения.
Для инициализации метода необходимо определить максимальное значение гиперпараметра, уровень относительно максимального значения, с которого learning rate будет увеличиваться.
Также по завершении полного цикла необходимо дополнительного уменьшить learning rate для дополнительного снижения отклонения функции потерь.
Ниже~(\ref{fig:osp}) приведен график изменения параметров learning rate и momentum в ходе one cycle policy.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/osp.png}
    \caption{Отладочная информация процесса обучения}
    \label{fig:osp}
\end{figure}

Подход применения гиперпараметра momentum заключается в использовании значения обновления весов с предыдущей итерации~\eqref{eq:17}.

\begin{equation}
    \label{eq:17}
    \omega_{i} = \omega_{j} - (\alpha \cdot \frac{\delta f(y, \tilde{y})}{\delta \omega_{j}} + \gamma \cdot \bigtriangleup \omega_{k})
\end{equation}

Здесь $\bigtriangleup \omega_{k}$ - изменение тренируемого параметра $\omega$ на предыдущей итерации, $\gamma$ - коэффициент momentum.
Использование данной техники помогает удержать спуск к минимуму при случайных шумах в текущем пакете данных.

\subsection{Корректировка маски}

Для устранения артефактов сегментации сетью использовались функции FindContours и DrawContours из состава библиотеки OpenCV\@.
В основе FindContours лежит алгоритм следования границы, описанный в~\autocite{Suzuki1985TopologicalSA}.

После нахождения контура, для региона, находящегося внутри него, вычисляется площадь.
При превышении эмпирически установленного порога, применяется DrawContours.
Основная задача такой доработки устранить влияние отражающих поверхностей на изображении на конечное качество сегментации~\ref{fig:find_contr}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/find_contr.png}
    \caption{Пример работы FindContours}
    \label{fig:find_contr}
\end{figure}

\section{Данные}

Эксперименты с обучением модели глубокой сверточной сети проводились на двух наборах данных.
Первый набор - это SkyFinder, открытый датасет, с размеченными под сегментацию неба изображениями.
Второй - объединение первого с изображениями, сделанными на камеру смартфона.
Примешивание к SkyFinder данных из целевого домена способствовало улучшению метрик качества на исходной валидационной выборке, так как
модель при обучении учитывала особенности цветопередачи и отличия в распределении двух классов на новых изображениях.
Таким образом увеличение разнообразия в данных уменьшило ковариантный сдвиг по доминирующим признакам в исходном датасете.

\subsection{Датасет SkyFinder}

SkyFinder представляет собой набор из 90.000 фотографий~\autocite{mihail2016sky}.
Все фотографии сделаны на статичные веб-камеры, расположенные вне зданий.
Для каждого изображения имеется размеченная бинарная маска с описанным в постановке задачи свойством: 1 обозначает класс принадлежности, 0 - обратный ему.
В верхней части изображений преобладает регион неба.
Средний процент пикселей относящихся к классу принадлежности равен 41 со стандартным отклонением в 16 процентов.
Изображения покрывают широкий диапазон освещённости и погодных условий, что препятствует переобучению на конкретных состояниях освещённости сцены.
При этом из-за статичности камер и их ограниченного количества - всего камер в отборе участвовало 53 штуки - модель при обучении
демонстрирует частые ложные срабатывания на близко расположенных детализированных объектах.
Ниже приведены примеры изображений из датасета~(\ref{fig:skyfinder}).

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/skyfinder.png}
    \caption{Примеры изображений из SkyFinder}
    \label{fig:skyfinder}
\end{figure}


\subsection{Датасет с синтетической разметкой}

В качестве дополнительных данных были использованы изображения с открытых интернет ресурсов.
Изображения были вручную очищены от тех, которые не имели в себе сегментов неба.
Небольшая часть из оставшихся была размечена с помощью графических редакторов.
Для разметки остальных использовалась сеть, обученная на данных из SkyFinder.
Такой подход позволяет разительно сократить временной ресурс, затрачиваемый на подготовку данных.
Подобная техника описывается в~\autocite{zhu2020improving} на примере миграции между датасетами CamVid и Cityscapes.

Для обучения сети на новом наборе данных был написан отдельный загрузчик на базе загрузчиков библиотеки глубокого обучения PyTorch.
Особенностью нового загрузчика является возможность совмещать в рамках одного пакета данные из разных источников на физическом диске.
При этом количественное отношение между разными данными представляется к настройке пользователю.
В рамках данной работы источников данных было два.
На пакет величиной 17 приходилось 13 изображений из датасета SkyFinder и 4 из данных с синтетической разметкой.
Термин "синтетическая" обусловлен использованием сети при разметки данных.
Соотношение в пакете было подобрано эмпирически.
Учитывалось, что большое количество изображений из новых данных может оказать негативный эффект на метриках качества,
из-за погрешностей в разметке.

Для получения данных с синтетической разметкой использовалась сеть, оубченная только на SkyFinder.
При этом на объединение данных сеть обучалась с нуля, не используя до этого подготовленные веса.


\section{Результаты}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/ocp_against_const.png}
    \caption{Сравнение результатов one cycle policy и константого значения learning rate}
    \label{fig:ocp_against_const}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/data_count_compare.png}
    \caption{Сравнение результатов для обучения с использованием синтетически размеченных данных (верхний ряд) с обучением только на SkyFinder}
    \label{fig:data_compare}
\end{figure}

На~\ref{fig:ocp_against_const} представлено сравнение техники one cycle policy настройки гиперпараметра~(голубой) с обучением,
в течение которого learning rate оставался постоянным~(бурый).
Как видно из графика, использование более высокого значения в первых итерациях позволило быстрее прийти к минимуму,
а последующее уменьшение learning rate улучшило сходимость.
На~\ref{fig:ocp_against_const}.a отображен график функции потерь, на~\ref{fig:ocp_against_const}.b и~\ref{fig:ocp_against_const}.c
графики значений метрики~$\mathrm{IoU}$ для классов неба и прочих объектов соответственно.

На~\ref{fig:data_compare} отражены результаты работы алгоритма сегментации.
Красным цветом выделен сгенерированный сегмент неба.
При использовании доменной адаптации~(верхний ряд) можно видеть лучшее качество работы алгоритма с сегментами неба,
в которых представлено большее цветовое разнообразие.
При этом подход без использования смены домена~(нижний ряд) склонен выделять как ложноположительные сегменты неба при близости цветов~(\ref{fig:data_compare}.5) между объектами разных классов,
так и оставлять ложноотрицательные регионы для резких переходов между цветам~(\ref{fig:data_compare}.6).

\Conc

В рамках данной работы был освещен вопрос семантического анализа фотографий искусственными нейронными сетями.
В качестве предмета была выбрана задача сегментации пикселей изображения на два класса: принадлежащих области неба и относящихся к прочим объектам на снимке.
Поставленная задача решалась применением глубоких сверточных сетей--ИНС со слоями свертки.
Качество алгоритма было улучшено с помощью корректировки результирующей маски алгоритмами компьютерного зрения.
При обучении сети использовались техники циклического изменения гиперпараметров learning rate и momentum,
что также способствовало увеличению метрики~$\mathrm{IoU}$.

Для устранения влияния различий между качеством изображений в данных датасета SkyFinder и данных целевого домен,
был применена доменная адаптация с помощью синтетически размеченных данных.
Замечу, что использование изображений с искусственной разметкой показывает достаточно высокие результаты
при низких временных затратах на подготовку данных.

Итоговое решение имеет средний показатель~$\mathrm{IoU}$ между классами равный~$94\%$.
Сериализованная на физическом носители модель занимает~$87.4\mathrm{MB}$.

\appendix

\section{Реализация сети c LinkNet декодером}

\begin{lstlisting}[python]
    class DecoderBlockLinkNet(nn.Module):
        def __init__(self, in_channels, n_filters):
            super().__init__()
            self.relu = nn.ReLU(inplace=True)

            self.conv1 = nn.Conv2d(in_channels, in_channels // 4, 1)
            self.norm1 = nn.BatchNorm2d(in_channels // 4)

            self.deconv2 = nn.ConvTranspose2d(in_channels // 4, in_channels // 4, kernel_size=4, stride=2, padding=1, output_padding=0)
            self.norm2 = nn.BatchNorm2d(in_channels // 4)

            self.conv3 = nn.Conv2d(in_channels // 4, n_filters, 1)
            self.norm3 = nn.BatchNorm2d(n_filters)

        def forward(self, x):
            x = self.conv1(x)
            x = self.norm1(x)
            x = self.relu(x)
            x = self.deconv2(x)
            x = self.norm2(x)
            x = self.relu(x)
            x = self.conv3(x)
            x = self.norm3(x)
            x = self.relu(x)
            return x


    class LinkNet34(nn.Module):
        def __init__(self, num_classes=1, num_channels=3, pretrained=True, debug_info=False,
                     save_decoder_outputs=False, save_encoder_outputs=False):
            super().__init__()
            assert num_channels == 3
            self.num_classes = num_classes
            filters = [64, 128, 256, 512] # кол-во карт признаков на разных уровнях
            resnet = models.resnet34(pretrained=pretrained)

            self.firstconv = resnet.conv1
            self.firstbn = resnet.bn1
            self.firstrelu = resnet.relu
            self.firstmaxpool = resnet.maxpool
            self.encoder1 = resnet.layer1
            self.encoder2 = resnet.layer2
            self.encoder3 = resnet.layer3
            self.encoder4 = resnet.layer4

            self.decoder4 = DecoderBlockLinkNet(filters[3], filters[2])
            self.decoder3 = DecoderBlockLinkNet(filters[2], filters[1])
            self.decoder2 = DecoderBlockLinkNet(filters[1], filters[0])
            self.decoder1 = DecoderBlockLinkNet(filters[0], filters[0])

            self.finaldeconv1 = nn.ConvTranspose2d(filters[0], 32, 3, stride=2)
            self.finalrelu1 = nn.ReLU(inplace=True)
            self.finalconv2 = nn.Conv2d(32, 32, 3)
            self.finalrelu2 = nn.ReLU(inplace=True)
            self.finalconv3 = nn.Conv2d(32, num_classes, 2, padding=1)

            self.dropout1 = nn.Dropout2d(0.5, False)
            self.dropout2 = nn.Dropout2d(0.3, False)

            self.with_debug_info = debug_info
            self.save_encoder = save_encoder_outputs
            self.save_decoder = save_decoder_outputs

        # noinspection PyCallingNonCallable
        def forward(self, x):
            x = self.firstconv(x)
            x = self.firstbn(x)
            x = self.firstrelu(x)
            x = self.firstmaxpool(x)
            e1 = self.encoder1(x)
            e2 = self.encoder2(e1)
            e3 = self.encoder3(e2)
            e4 = self.encoder4(e3)

            d4 = self.decoder4(e4) + e3
            d3 = self.decoder3(d4) + e2
            d2 = self.decoder2(d3) + e1
            d1 = self.decoder1(d2)

            f1 = self.finaldeconv1(d1)
            f2 = self.finalrelu1(f1)
            dr1 = self.dropout1(f2)
            f3 = self.finalconv2(dr1)
            f4 = self.finalrelu2(f3)
            dr2 = self.dropout2(f4)
            f5 = self.finalconv3(dr2)

            x_out = F.log_softmax(f5, dim=1)

            _ = self.with_debug_info and __print_info__(f5, x_out)
            _ = self.save_encoder and __save_pre_encoder_outputs__([x])
            _ = self.save_encoder and __save_encoder_outputs__([e1, e2, e3, e4])
            _ = self.save_decoder and __save_decoder_outputs__([d1, d2, d3, d4])
            _ = self.save_decoder and __save_classifier_outputs__([dr1])

            return x_out
\end{lstlisting}

Строчки 1--25: Класс декодер-блока по схеме LinkNet.
Функция forward (стр. 15) -- прямой проход по сети.
Библиотека глубокого обучения PyTorch, при использовании слоев из ее состава,
позволяет не определять функции для обновления весов алгоритмам обратного распространения.
В замен этого на каждой итерации обучения используются предописанные в самой библиотеке вычисления.

Строчки 28--96: Класс с полным описанием архитектуры сети.

Строчки 66--73: Исполнение енкодер-части сети.

Строчки 75--88: Исполнение декодер-части сети с последующей классификацией и применением результирующего Softmax.

Строчки 90--94: Снятие значений карт признаков с различных уровней сети и вывод отладочной информации.
За счет применения механизма ленивого выполнения в языке Python,
получается отказаться от оператора условного выбора, выполняемого за большое кол-во инструкций процессора

\section{Реализация многоресурсного загрузчика}

\begin{lstlisting}[python]
    class SeveralSourceDataset(t_Dataset):
    _modes = [
        "absolute", "relative"
    ]

    def __init__(self, sources: Union[List[Union[Path, str]], Tuple[Union[Path, str]], Path, str],
                 batch_consistency: Union[List[int], Tuple[int]],
                 label_from_func: Callable, transforms: List[Any], size: int):
        t = type(sources)
        if t == Path or t == str:
            sources = [sources]

        self._sources: List[Path] = []
        for s in sources:
            if type(s) == str:
                self._sources.append(Path(s))
            else:
                self._sources.append(s)

        self._sources_count = len(self._sources)

        self._bc = batch_consistency

        if len(self._bc) != self._sources_count:
            raise RuntimeError("Unexpected consistency value")

        self._current_index = 0
        self._index_to_source = []
        index: int = 0
        for bc in self._bc:
            self._index_to_source += [index for _ in range(bc)]
            index += 1

        self.images: List[List[Path]] = []
        self.labels: List[List[Path]] = []

        self._len: int = 0
        index: int = 0
        for source in self._sources:
            self.images.append([])
            self.labels.append([])
            for image in source.iterdir():
                self.images[index].append(image)
                self.labels[index].append(label_from_func(image))
            self._len += len(self.images[index])
            index += 1

        self._inner_indexes: List[int] = [0 for _ in range(self._sources_count)]
        if type(transforms) != list:
            raise RuntimeError(
                "Unexpected transforms type. Should be list of fastai.vision.image.RandTransform or list of list of fastai.vision.image.RandTransform.")
        if len(transforms) > 0:
            if type(transforms[0]) == fastai.vision.image.RandTransform:
                transforms = [transforms]

        self.transform: List[List[Any]] = transforms
        self._size = size

    def __len__(self) -> int:
        return self._len

    def get(self, item):
        mod = len(self._index_to_source)
        index = self._index_to_source[item % mod]
        inner_index = self._inner_indexes[index]
        img = open_image(self.images[index][inner_index])
        label = open_mask(self.labels[index][inner_index], div=True)
        inner_index += 1
        self._inner_indexes[index] = inner_index % len(self.images[index])
        return img, label

    def __getitem__(self, item):
        img, lbl = self.get(item)
        img = img.resize(self._size).data
        lbl = lbl.resize(self._size).data.squeeze(dim=0)
        return img, lbl
\end{lstlisting}

% Печать списка литературы (библиографии)
\printbibliography[%{}
    heading=bibintoc%
%,title=Библиография % если хочется это слово
]
% Файл со списком литературы: biblio.bib
% Подробно по оформлению библиографии:
% см. документацию к пакету biblatex-gost
% http://ctan.mirrorcatalogs.com/macros/latex/exptl/biblatex-contrib/biblatex-gost/doc/biblatex-gost.pdf
% и огромное количество примеров там же:
% http://mirror.macomnet.net/pub/CTAN/macros/latex/contrib/biblatex-contrib/biblatex-gost/doc/biblatex-gost-examples.pdf

\end{document}
